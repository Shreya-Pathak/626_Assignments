{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.stem.porter import *\nfrom nltk.classify import MaxentClassifier\nimport tensorflow as tf\nimport numpy as np\nfrom io import open\nimport os\nprint(os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadGloveModel(File):\n    print(\"Loading Glove Model\")\n    f = open(File,'r')\n    gloveModel = {}\n    for line in f:\n        splitLines = line.split()\n        word = splitLines[0]\n        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n        gloveModel[word] = wordEmbedding\n    print(len(gloveModel),\" words loaded!\")\n    return gloveModel\nglovemod=loadGloveModel(\"/kaggle/input/glove6b50dtxt/glove.6B.50d.txt\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"boi_full_list = [] #store all the boi tags that occur in the training set\nBO_list = ['B', 'I','O']\nlabeled_features = []\nwordStartList = []\nboi_end_list = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"POS_dict={'X':0}\nposcnt=1\nwith open(\"/kaggle/input/conll-corpora/conll2000/conll2000/train.txt\", \"r\") as f:\n    for line in f:\n        line=line.strip()\n        if line!='':\n            POS_tag=line.split()[1]\n            if POS_tag not in POS_dict:\n                POS_dict[POS_tag]=poscnt\n                poscnt+=1\ndef get_vector_POS(tag):\n    ans=[0]*len(POS_dict)\n    ans[POS_dict[tag]]=1\n    return ans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(POS_dict)\n# print(\"hey\")\n# output_file = open(\"bo_output.txt\", \"wb\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boi_full_list = [] #store all the boi tags that occur in the training set\nlabeled_features = []\nwordStartList = []\nboi_end_list = []\ntraining_file = open(\"/kaggle/input/conll-corpora/conll2000/conll2000/train.txt\", \"r\")\nprevious_BOI = \"start\"\ninput_file = training_file\nchange_of_sentence_flag=1\nst = False\ni = 0\nfor line in input_file:\n    #print(line)\n    s = re.match(r'^\\s*$', line)  #find empty line\n    if s:\n        i=0\n        change_of_sentence_flag = 1\n        previous_BOI = \"start\"\n    else: \n        sentenceList = line.split()\n        word = sentenceList[0]\n        tag = sentenceList[1]\n        boi = (sentenceList[2].split('-'))[0]\n        #print(boi)\n        \n        #store words that are begining of the sentence\n        if change_of_sentence_flag == 1:\n            wordStartList.append(word)\n            if st:\n                boi_end_list.append(boi_full_list[-1])\n            change_of_sentence_flag = 0\n        boi_full_list.append(boi)\n        prev_w, prev_t, prev_w2, prev_t2, prev_bi, prev_bi2 = 'X', 'X', 'X', 'X', 'start', 'start'\n        next_w, next_t, next_w2, next_t2 = 'X', 'X', 'X', 'X'\n        if i>0:\n            prev_w = labeled_features[-1][0]\n            prev_t = labeled_features[-1][1]\n            prev_bi = labeled_features[-1][2]\n            labeled_features[-1][9] = word\n            labeled_features[-1][10] = tag\n        if i>1:\n            prev_w2 = labeled_features[-2][0]\n            prev_t2 = labeled_features[-2][1]\n            prev_bi2 = labeled_features[-2][2]\n            labeled_features[-2][11] = word\n            labeled_features[-2][12] = tag\n        item = [word, tag, boi, prev_w, prev_t, prev_bi, prev_w2, prev_t2,prev_bi2, next_w, next_t, next_w2, next_t2 ]\n        #print(item) if s:\n        w=0\n        change_of_sentence_flag = 1\n        previous_BOI = \"start\"\n        labeled_features.append(item)\n        previous_BOI = boi\n        st = True\n        i+=1\n        #labeled_features \n\nboi_end_list.append(boi_full_list[-1])\n\ninput_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[print(x) for x in labeled_features[35:40]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = PorterStemmer()\nprint(len(labeled_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MEMM_features(item):\n    # 0word, 1tag, 2boi, 3prev_w, 4prev_t, 5prev_bi, 6prev_w2, 7prev_t2,8prev_bi2, 9next_w, 10next_t, 11next_w2, 12next_t2  \n    features = {}\n    allbois=['B', 'I','O','start']\n    emb1 = glovemod.get(item[0].lower(),glovemod['.'])\n    for j in range(emb1.shape[0]):\n            features[\"cw\"+str(j)]=emb1[j]\n            \n    emb1 = glovemod.get(item[3].lower(),glovemod['.'])\n    for j in range(emb1.shape[0]):\n            features[\"pw\"+str(j)]=emb1[j]\n    \n    emb1 = glovemod.get(item[6].lower(),glovemod['.'])\n    for j in range(emb1.shape[0]):\n            features[\"pw2\"+str(j)]=emb1[j]\n            \n    emb1 = glovemod.get(item[9].lower(),glovemod['.'])\n    for j in range(emb1.shape[0]):\n            features[\"nw\"+str(j)]=emb1[j]\n            \n    emb1 = glovemod.get(item[11].lower(),glovemod['.'])\n    for j in range(emb1.shape[0]):\n            features[\"nw2\"+str(j)]=emb1[j]\n\n#     Removed POS tags\n    cnter=0\n    for x in get_vector_POS(item[1]):\n        features['current_tag'+str(cnter)]=x\n        cnter+=1\n\n    cnter=0\n    for x in get_vector_POS(item[4]):\n        features['prev_tag'+str(cnter)]=x\n        cnter+=1\n    cnter=0\n    for x in get_vector_POS(item[7]):\n        features['[prev_tag2'+str(cnter)]=x\n        cnter+=1\n    cnter=0\n    for x in get_vector_POS(item[10]):\n        features['next_tag'+str(cnter)]=x\n        cnter+=1\n    cnter=0\n    for x in get_vector_POS(item[12]):\n        features['next_tag2'+str(cnter)]=x\n        cnter+=1   \n    for i in range(4):\n        features['prev_bi'+str(i)]=0\n    features['prev_bi'+str(allbois.index(item[5]))]=1\n    features['capitalization'] = int(word[0].isupper())\n    features['start_of_sentence'] = int(word in wordStartList)\n    features['cap_start'] = int(word not in wordStartList and word[0].isupper())\n    token = item[0]\n    features['ends_with_ly']    = float(token.endswith('ly'))\n    features['ends_with_ment']  = float(token.endswith('ment'))\n    features['ends_with_able']  = float(token.endswith('able') or token.endswith('ible'))\n    features['ends_with_fy' ]   = float(token.endswith('fy'))\n    features['ends_with_al']    = float(token.endswith('al'))\n    f1=list(features.items())\n    features=[x[1] for x in f1]\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r=np.array(MEMM_features(labeled_features[0]))\n#print(r)\nprint(r.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labeled_featuresets = [MEMM_features(item) for item in labeled_features]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labeled_featuresets[0][-10:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = np.array(labeled_featuresets)\nprint(len(train_set))\n#print(train_set[0])\nprint(train_set.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = train_set[0].shape[0]\nBO_list = ['B', 'I','O']\ntrain_labels=np.array([BO_list.index(x) for x in boi_full_list])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((train_labels.dtype))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_set.shape)\nprint(train_set.dtype)\nprint(type(train_set[0]))\nprint(type(train_set))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nwith strategy.scope():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.Input(shape=(input_shape,)))\n    #model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(len(BO_list), activation='softmax'))# changed here\n    model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(0.001),metrics=['accuracy'])\n    model.fit(x=train_set,y=train_labels,validation_split=0.1,epochs=5,batch_size = 128 * strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib\njoblib.dump(train_set, 'train_features.pkl')\njoblib.dump(train_labels,'train_labels.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MEMM(preds):\n    BOI_list = ['B', 'I','O']\n    tRange = len(BOI_list)\n    wRange = int(len(preds)//3+1)\n    #word, tag, boi, prev_w, prev_t, prev_bi, prev_w2, prev_t2, next_w, next_t, next_w2, next_t2\n    max_len = 300\n    viterbi = [[0 for x in range(max_len)] for x in range(max_len)] \n    backpointer = [['' for x in range(max_len)] for x in range(max_len)] \n    for t in range(tRange):#t = 0,1,2\n        posterior = float(preds[0][t])\n        viterbi[t][1] = posterior\n        backpointer[t][1] = 0 #stand for q0 (start point)\n\n    #for word w from 2 to T\n    maxViterbi = 0\n    maxPreviousState = 0 \n    maxPreTerminalProb = 0\n    for w in range (1, wRange):\n        for t in range (tRange):\n            posterior = float(preds[(w-1)*3+1][t])\n            maxViterbi = float(viterbi[0][w]) * posterior\n            maxPreviousState = 0\n            for i in range (1, tRange):\n                posterior = float(preds[(w-1)*3+1+i][t])\n                if float(viterbi[i][w]) * posterior > maxViterbi:\n                    maxViterbi = float(viterbi[i][w]) * posterior\n                    maxPreviousState = i #content BOI_List[i]\n            viterbi[t][w+1] = maxViterbi\n            backpointer[t][w+1] = BOI_list[maxPreviousState] #points to the matrix x axis (max previous)\n\n            maxViterbi = 0\n            maxPreviousState = 0 \n            maxPreTerminalProb = 0\n    #termination step\n    maxPreTerminalProb = float(viterbi[0][wRange] )#* float(dicE[BOI_list[0]][\"END\"])\n    \n    maxPreviousState = 0\n    for i in range (1, tRange):\n\n        if float(viterbi[i][wRange]) > maxPreTerminalProb:\n            maxPreTerminalProb = float(viterbi[i][wRange]) #* float(dicE[BOI_list[i]][\"END\"]) \n\n            maxPreviousState = i\n\n    viterbi[tRange][wRange+1] = maxPreTerminalProb \n    backpointer[tRange][wRange+1] = BOI_list[maxPreviousState]\n#return POS tag path \n    pathReverse = [BOI_list[maxPreviousState]]\n    maxPreviousTag = BOI_list[maxPreviousState]\n\n    i = 0\n    while i < (wRange -1):\n        pathReverse.append(backpointer[BOI_list.index(maxPreviousTag)][wRange - i])\n        maxPreviousTag = backpointer[BOI_list.index(maxPreviousTag)][wRange - i]\n        i = i + 1 \n\n#reverse the path to make it correct\n    index = len(pathReverse)\n    path = []\n    while index >= 1 :\n        path.append(pathReverse[index - 1])\n        index = index -1 \n    return path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_file = open(\"/kaggle/input/conll-corpora/conll2000/conll2000/test.txt\", \"r\")\nwordList = [] #store words in a sentence\ntagList = [] #store part-of-speech tag in a sentence \nboiList = [] #store boi tags in a sentence \nind_list=[]\nindl_list = []\nboi_list=[]\nallWords = []\n#prob_table = {} #stpre the posterior\nprevious_BOI = \"start\"\nBOI_list = ['B', 'I','O']\ntRange = len(BOI_list)\ntot_corr=0\ntot = 0\n\nw=0\ntest_data = []\ntest_labels = []\ninput_file = testing_file\nfor line in input_file:\n    \n    if line.strip() != '': #if not empty do following \n        sentenceList = line.split()\n        word = sentenceList[0]\n        tag = sentenceList[1]\n        boi = (sentenceList[2].split('-'))[0]\n        wordList.append(word)\n        tagList.append(tag)\n        boiList.append(boi)\n        wp1 = 'X' if w==0 else wordList[w-1]\n        wp2 = 'X' if w<2 else wordList[w-2]\n        tp1 = 'X' if w==0 else tagList[w-1]\n        tp2 = 'X' if w<2 else tagList[w-2]\n        wn1 = 'X' #if w>wRange-2 else wordList[w+1]\n        wn2 = 'X' #if w>wRange-3 else wordList[w+2]\n        tn1 = 'X' #if w>wRange-2 else tagList[w+1]\n        tn2 = 'X' #if w>wRange-3 else tagList[w+2]\n        item = [word, tag, 'BIO', wp1, tp1, 'BIO', wp2, tp2,'ununsed', wn1, tn1, wn2, tn2 ]\n        if w==1:\n            test_data[-1][9] = word\n            test_data[-1][10] = tag\n        elif w>1:\n            for i in range(tRange):\n                test_data[-1-i][9] = word\n                test_data[-1-i][10] = tag\n        if w==2:\n            test_data[-1-tRange][11] = word\n            test_data[-1-tRange][12] = tag\n        elif w>2:\n            for i in range(tRange):\n                test_data[-1-tRange-i][11] = word\n                test_data[-1-tRange-i][12] = tag\n        if w==0:\n            item1 = item.copy()\n            item1[5] = \"start\"\n            test_data.append(item1)\n            #test_labels.append(boi)\n        else:\n            for i in range(tRange):\n                item1 = item.copy()\n                item1[5] = BOI_list[i]\n                #print(BOI_list[i])\n                test_data.append(item1)\n                #test_labels.append(boi)\n        w+=1\n        test_labels.append(boi)\n        #print (word, tag, boi)\n#store words that are begining of the sentence\n#store tags that are the begining of the sentence\n#store the end of sentence tag in tagEndList\n        if change_of_sentence_flag == 1:\n            wordStartList.append(word)\n            change_of_sentence_flag = 0\n    s = re.match(r'^\\s*$', line)  #find empty line\n    if s:\n        w=0\n        change_of_sentence_flag = 1\n        previous_BOI = \"start\"\n        ind_list.append(len(test_data)-1)\n        indl_list.append(len(test_labels)-1)\n        allWords+=wordList\n        wordList = [] # refresh word list\n        tagList = []\n        boiList = []\n\ninput_file.close()\n#print(tot_corr/tot)\n#output_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_data[1:4])\nprint(test_labels[0])\nprint(len(test_data))\nprint(len(test_labels))\nprint(len(ind_list))\nprint(len(indl_list))\nprint(ind_list[0:10])\nprint(indl_list[0:10])\nprint(len(allWords))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test = [MEMM_features(item) for item in test_data]\ntest_set = np.array(final_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(test_set))\nprint(np.sum(test_set[1]==test_set[2]))\nprint(test_set.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BO_list = ['B', 'I','O']\ntest_labels_ind=np.array([BO_list.index(x) for x in test_labels])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    predictions = model.predict(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev = 0\nprevl = 0\ntot_corr = 0\ntot = 0\nfinal_pred = []\n#len(ind_list)\nfor i in range(len(ind_list)):\n    x1 = ind_list[i]\n    x2 = indl_list[i]\n    test_list = predictions[prev:x1+1]\n    true_val = test_labels[prevl:x2+1]\n    prev = x1+1\n    prevl = x2+1\n    path = MEMM(test_list)\n    final_pred+=path\n#     print(path)\n#     print(true_val)\n    metric = np.array(true_val)==np.array(path)\n    acc = np.sum(metric)/len(path)\n    #print(acc)\n    tot_corr += np.sum(metric)\n    tot += len(path)\n\nprint(tot_corr/tot)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\ndef get_report(y_true, y_pred, classes):\n    clf_report = classification_report(y_true, y_pred, labels=classes, zero_division=0)\n    clf_report = clf_report.replace('\\n\\n', '\\n')\n    clf_report = clf_report.replace('micro avg', 'micro_avg')\n    clf_report = clf_report.replace('macro avg', 'macro_avg')\n    clf_report = clf_report.replace('weighted avg', 'weighted_avg')\n    clf_report = clf_report.replace(' / ', '/')\n    lines = clf_report.split('\\n')\n\n    class_names, plotMat, support = [], [], []\n    for line in lines[1:]:\n        t = line.strip().split()\n        if len(t) < 2:\n            continue\n        v = [float(x) for x in t[1: len(t) - 1]]\n        if len(v) == 1 : v = v * 3\n        support.append(int(t[-1]))\n        class_names.append(t[0])\n        plotMat.append(v)\n    plotMat = np.array(plotMat)\n    support = np.array(support)\n    return class_names, plotMat, support\n\ndef get_scores(y_true, y_pred, classes):\n    correct, wrong = {}, {}\n    for tag in classes:\n        correct[tag] = 0\n        wrong[tag] = 0\n        \n    for tag, pred in zip(y_true, y_pred):\n        if tag == pred:\n            correct[tag] += 1\n        else:\n            wrong[tag] += 1\n            \n    scores = []\n    total = len(y_true)\n    for tag in classes:\n        cur = np.array([correct[tag], wrong[tag]])\n        scores.append(cur / total)\n    return np.array(scores)\n    \ndef plot_confusion_matrix(classes, mat, normalize=True, cmap=plt.cm.Blues):\n    cm = np.copy(mat)\n    title = 'Confusion Matrix (without normalization)'\n    if normalize:\n        cm = cm.astype('float') / np.sum(cm, axis=1, keepdims=True)\n        title = title.replace('without', 'with')\n    plt.clf()    \n    fig, ax = plt.subplots(figsize=(20,10))\n    ax.set_title(title, y=-0.06, fontsize=22)\n    ax.xaxis.set_ticks_position('top')\n    ax.xaxis.set_label_position('top')\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.clim(vmin=0.0, vmax=1.0)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = np.max(cm) / 2\n    thresh = 1 / 2\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            color = \"white\" if (cm[i, j] > thresh) else \"black\"\n            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=color)\n    plt.ylabel('True label',fontsize=22)\n    plt.xlabel('Predicted label', fontsize=22)\n    plt.tight_layout()\n    plt.savefig('confusion_matrix.png', bbox_inches=\"tight\", transparent=True)\n    plt.show()\n    \ndef plot_clf_report(classes, plotMat, support, cmap=plt.cm.Blues):\n    title = 'Classification Report'\n    xticklabels = ['Precision', 'Recall', 'F1-score']\n    yticklabels = ['{0} ({1})'.format(classes[idx], sup) for idx, sup in enumerate(support)]\n    plt.clf()\n    fig, ax = plt.subplots(figsize=(20,10))\n    ax.set_title(title, y=-0.06, fontsize=22)\n    ax.xaxis.set_ticks_position('top')\n    ax.xaxis.set_label_position('top')\n    ax.xaxis.set_tick_params(labelsize=18)\n    ax.yaxis.set_tick_params(labelsize=14)\n    plt.imshow(plotMat, interpolation='nearest', cmap=cmap, aspect='auto')\n    plt.clim(vmin=0.0, vmax=1.0)\n    plt.colorbar()\n    plt.xticks(np.arange(3), xticklabels, rotation=0)\n    plt.yticks(np.arange(len(classes)), yticklabels)\n    thresh = np.max(plotMat) / 2\n    thresh = 1 / 2\n    for i in range(plotMat.shape[0]):\n        for j in range(plotMat.shape[1]):\n            color = \"white\" if (plotMat[i, j] > thresh) else \"black\"\n            plt.text(j, i, format(plotMat[i, j], '.2f'), horizontalalignment=\"center\", color=color, fontsize=14)\n\n    plt.xlabel('Metrics',fontsize=22)\n    plt.ylabel('Classes',fontsize=22)\n    plt.tight_layout()\n    plt.savefig('classification_report.png', bbox_inches=\"tight\", transparent=True)\n    plt.show()\n    \ndef plot_tag_scores(classes, scores, normalize=True):\n    plt.clf()\n    width = 0.45\n    fig, ax = plt.subplots(figsize=(20,10))\n    ax.xaxis.set_tick_params(labelsize=18, rotation=25)\n    ax.yaxis.set_tick_params(labelsize=18)\n    range_bar1 = np.arange(len(classes))\n    rects1 = ax.bar(range_bar1, tuple(scores[:, 0]), width, color='b')\n    rects2 = ax.bar(range_bar1 + width, tuple(scores[:, 1]), width, color='r')\n\n    ax.set_ylabel('Scores',fontsize=22)\n    ax.set_title('Tag scores', fontsize=22)\n    ax.set_xticks(range_bar1 + width / 2)\n    ax.set_xticklabels(classes)\n\n    ax.legend((rects1[0], rects2[0]), ('Correct', 'Wrong'), fontsize=20)\n    plt.legend()\n    plt.savefig('tag_scores.png', bbox_inches=\"tight\", transparent=True)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true=test_labels\ny_pred=final_pred\nprint(len(y_true))\nprint(len(final_pred))\nclasses = ['B','I','O']\nclass_names, report, support = get_report(y_true, y_pred, classes)\ncm = confusion_matrix(y_true, y_pred, labels=classes)\nscores = get_scores(y_true, y_pred, classes)\nplot_clf_report(class_names, report, support)\nplot_confusion_matrix(classes, cm)\nplot_tag_scores(classes, scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errswords=[]\ncorrectlabels=[]\nerrlabels=[]\nj=0\nfor i in range(len(test_labels)):\n    if(i>indl_list[j]):\n        j+=1\n    if test_labels[i]!=final_pred[i]:\n        errswords.append([allWords[i-1] if ((i>0 and j==0) or (j>0 and i>indl_list[j-1]+1)) else '##',allWords[i],allWords[i+1] if i<indl_list[j]-1 else '##'])\n        correctlabels.append([test_labels[i-1] if ((i>0 and j==0) or (j>0 and i>indl_list[j-1]+1)) else '##',test_labels[i],test_labels[i+1] if i<indl_list[j]-1 else '##'])\n        errlabels.append([final_pred[i-1] if ((i>0 and j==0) or (j>0 and i>indl_list[j-1]+1)) else '##',final_pred[i],final_pred[i+1] if i<indl_list[j]-1 else '##'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(errswords[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(errswords))\nx=[print((str(i[0])  if i[0]!=None else '##' )+' '+str(i[1])+' '+(str(i[2])  if i[2]!=None else '##' )+' ( correct: '+j[0]+' '+j[1]+' '+j[2]+ ' predicted: '+k[0]+' '+k[1]+' '+k[2]+' )') for i,j,k in zip(errswords[:100],correctlabels[:100],errlabels[:100])]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}